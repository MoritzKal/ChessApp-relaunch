
x-ports: &ports
  prometheus: ${PROMETHEUS_PORT:-9090}
  grafana: ${GRAFANA_PORT:-3000}
  loki: ${LOKI_PORT:-3100}
  mlflow: ${MLFLOW_PORT:-5000}
  minio_s3: ${MINIO_S3_PORT:-9000}
  minio_console: ${MINIO_CONSOLE_PORT:-9001}
  postgres: ${POSTGRES_PORT:-5432}

networks:
  infra_chs_net: {}

volumes:
  db-data: {}
  minio-data: {}
  grafana-data: {}
  prometheus-data: {}
  loki-data: {}
  mlflow-data: {}

services:
  db:
    image: postgres:16
    container_name: chs_db
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - db-data:/var/lib/postgresql/data
    networks: [infra_chs_net]
    healthcheck:
      test: [ "CMD-SHELL","pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}" ]
      interval: 5s
      timeout: 5s
      retries: 20
    restart: unless-stopped

  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    volumes:
      - minio-data:/data
    # Kein Healthcheck: Images bringen oft kein wget/curl mit; Readiness übernimmt create-buckets
    ports:
      - "${MINIO_S3_PORT:-9000}:9000"
      - "${MINIO_CONSOLE_PORT:-9001}:9001"

  create-buckets:
    image: minio/mc:latest
    depends_on:
      minio:
        condition: service_started
    entrypoint: >
      sh -c '
      set -e;
      until mc alias set local http://minio:9000 "${MINIO_ROOT_USER}" "${MINIO_ROOT_PASSWORD}" >/dev/null 2>&1; do
        echo "waiting for minio..."; sleep 2;
      done;
      mc mb -p local/chess-datasets || true;
      mc mb -p local/chess-models || true;
      echo "buckets ready";
      '

  mlflow:
    build: mlflow
    container_name: chs_mlflow
    environment:
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      AWS_DEFAULT_REGION: us-east-1
    command: >
      sh -c "mlflow server \
      --backend-store-uri sqlite:////mlflow/mlflow.db \
      --default-artifact-root s3://mlflow \
      --host 0.0.0.0 --port ${MLFLOW_PORT:-5000}"
    ports:
      - "${MLFLOW_PORT:-5000}:5000"
    volumes:
      - mlflow-data:/mlflow
    depends_on:
      minio:
        condition: service_started
        required: true
      create-buckets:
        condition: service_completed_successfully
    networks: [infra_chs_net]

  prometheus:
    image: prom/prometheus:latest
    container_name: chs_prometheus
    # Kein Env in Config nötig; Token wird als Datei gemountet (/run/secrets/monitoring_token)
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
      - --web.enable-lifecycle
    volumes:
      - prometheus-data:/prometheus
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/alerts/:/etc/prometheus/alerts/:ro
      - ./prometheus/secrets:/run/secrets:ro
      - ./prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml:ro
      - ./infra/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:9090/-/ready || curl -fsS http://localhost:9090/-/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    networks: [infra_chs_net]

  loki:
    image: grafana/loki:2.9.6
    container_name: chs_loki
    command: -config.file=/etc/loki/config/loki-config.yaml
    volumes:
      - loki-data:/loki
      - ./loki/loki-config.yaml:/etc/loki/config/loki-config.yaml:ro
    ports:
      - "${LOKI_PORT:-3100}:3100"
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:3100/ready || curl -fsS http://localhost:3100/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    networks: [infra_chs_net]

  promtail:
    image: grafana/promtail:latest
    container_name: chs_promtail
    command: -config.file=/etc/promtail/config.yml
    volumes:
      - ./promtail/promtail-config.yml:/etc/promtail/config.yml:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    depends_on:
      - loki
    ports:
      - "9080:9080"
    networks: [infra_chs_net]

  grafana:
    image: grafana/grafana:latest
    container_name: chs_grafana
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
      GF_AUTH_ANONYMOUS_ENABLED: "true"
      GF_AUTH_ANONYMOUS_ORG_ROLE: "Editor"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:3000/api/health || curl -fsS http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    depends_on:
      prometheus:
        condition: service_healthy
      loki:
        condition: service_healthy
    networks: [infra_chs_net]

  ml:
    build:
      context: ../ml
      dockerfile: Dockerfile
    working_dir: /app
    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5000
      ML_S3_ENDPOINT: http://minio:9000
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      AWS_REGION: us-east-1
      DEFAULT_USERNAME: ${CHESS_USERNAME:-M3NG00S3}
      ML_ARTIFACT_BUCKET: mlflow
      PROMETHEUS_MULTIPROC_DIR: /tmp/chs_prom
    depends_on:
      - minio
      - mlflow
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8000/health"]
      interval: 10s
      timeout: 3s
      retries: 10
    ports:
      - "8000:8000"
    volumes:
      - ../data:/app/ml/data
      - ../out:/app/ml/out
    networks: [ infra_chs_net ]
    restart: unless-stopped

  serve:
    build: ../serve
    container_name: chs_serve
    environment:
      ML_S3_ENDPOINT: http://minio:9000
      AWS_ACCESS_KEY_ID: minio_chs
      AWS_SECRET_ACCESS_KEY: chs_minio_password_change_me
      AWS_REGION: us-east-1
      DEFAULT_USERNAME: M3NG00S3
    ports:
      - "8001:8001"
    depends_on:
      - minio
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:8001/health | grep -q '\"status\":\"ok\"'"]
      interval: 10s
      timeout: 3s
      retries: 10
      start_period: 10s
    networks: [ infra_chs_net ]
    restart: unless-stopped
  api:
    build:
      context: ..
      dockerfile: /api/api-app/Dockerfile
    container_name: chs_api
    env_file:
      - ../.env
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      CHESS_USERNAME: ${CHESS_USERNAME:-M3NG00S3}
      SPRING_DATASOURCE_URL: jdbc:postgresql://db:5432/$${POSTGRES_DB}
      SPRING_DATASOURCE_USERNAME: ${POSTGRES_USER}
      SPRING_DATASOURCE_PASSWORD: ${POSTGRES_PASSWORD}
      LOGGING_LEVEL_org.springdoc: DEBUG
      LOGGING_LEVEL_org.springdoc_web: INFO
      LOGGING_LEVEL_org_springframework: INFO
      SPRINGDOC_SWAGGER_UI_URL: /v3/api-docs/v1
      SPRINGDOC_SWAGGER_UI_DISABLE_SWAGGER_DEFAULT_URL: "true"
      SPRINGDOC_GROUPS_ENABLED: "true"
      SPRINGDOC_CACHE_DISABLED: "false"
      S3_ENDPOINT: http://minio:9000
      S3_REGION: us-east-1
      S3_ACCESS_KEY: ${MINIO_ROOT_USER}
      S3_SECRET_KEY: ${MINIO_ROOT_PASSWORD}
      
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      AWS_REGION: us-east-1
      ML_S3_ENDPOINT: http://minio:9000
      # JWT secrets and direct Spring property
      API_JWT_SECRET: ${API_JWT_SECRET}
      APP_SECURITY_JWT_SECRET: ${APP_SECURITY_JWT_SECRET}
    
      # Enable dev token mint endpoint (disable in prod!)
      APP_SECURITY_DEV_TOKEN_ENABLED: "true"

    depends_on:
      db:
        condition: service_healthy
    ports:
      - "8080:8080"
    networks: [ infra_chs_net ]
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    environment:
      - VITE_API_BASE=http://api:8080
    ports:
      - "8081:8081"
    depends_on:
      - api

  fe-dev:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    environment:
      - VITE_API_BASE=http://localhost:8080
    volumes:
      - ./frontend:/app
      - /app/node_modules
    ports:
      - "5173:5173"

