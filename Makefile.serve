SHELL := /bin/sh
COMPOSE_FILES := -f infra/compose.serve.yml

.PHONY: serve-up serve-down serve-logs serve-bench

serve-up:
	docker compose $(COMPOSE_FILES) up --build -d serve

serve-down:
	docker compose $(COMPOSE_FILES) down --remove-orphans

serve-logs:
	docker compose $(COMPOSE_FILES) logs -f serve

# Simple local latency benchmark (prints p95); requires service to be running on localhost:8001
serve-bench:
		python3 - <<'PY'
	import json, time, urllib.request, statistics
	FENS = [
	"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1",
	"rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1",
	"rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2",
	"rnbqkbnr/pp1ppppp/8/2p5/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2",
	"r1bqk1nr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 3 4",
	"rnbqkbnr/ppp1pppp/8/3p4/2P5/8/PP1PPPPP/RNBQKBNR w KQkq - 0 2",
	"8/8/8/8/4k3/8/4K3/8 w - - 0 1",
	"r2q1rk1/pp1nbppp/2np1n2/2p1p3/2P1P3/1PNPB1P1/PB1N1PBP/R2Q1RK1 w - - 0 10",
	"r3k2r/pppq1ppp/2n1bn2/3p4/3P4/2N1PN2/PPPQ1PPP/R3K2R w KQkq - 0 10",
	"r1bq1rk1/ppp2ppp/2n2n2/3pp3/1b1PP3/2N2N2/PPP1BPPP/R1BQ1RK1 w - - 0 7",
	]
	URL = "http://127.0.0.1:8001/predict"
	durations = []
	body_tpl = lambda fen: json.dumps({"fen": fen}).encode("utf-8")
	for fen in FENS:
	    for _ in range(20):
		t0 = time.perf_counter()
		req = urllib.request.Request(URL, data=body_tpl(fen), headers={"Content-Type": "application/json"})
		with urllib.request.urlopen(req) as r:
		    json.load(r)
		durations.append(time.perf_counter() - t0)
	p95 = sorted(durations)[int(0.95*len(durations))-1]
	print(f"calls={len(durations)} p95={p95*1000:.1f}ms")
	assert p95 <= 0.150, "p95 exceeds 150ms"
	PY
